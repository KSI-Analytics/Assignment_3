{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe6c7f0",
   "metadata": {},
   "source": [
    "Implementing Huggingface streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c6b137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from datasets) (3.10.5)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\katoy\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, multiprocess, huggingface-hub, datasets\n",
      "Successfully installed datasets-3.5.0 huggingface-hub-0.30.2 multiprocess-0.70.16 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9b05cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af2cc489968435ab91bfc1ed608bdb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "meta_All_Beauty.jsonl:   0%|          | 0.00/213M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katoy\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\katoy\\.cache\\huggingface\\hub\\datasets--McAuley-Lab--Amazon-Reviews-2023. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6ad6e6ff0e46359dd3d932b1ebfe44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating full split:   0%|          | 0/112590 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits dict_keys(['full'])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b586c1fd0564592977d9f0944305f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All_Beauty.jsonl:   0%|          | 0.00/327M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5825b5c12dc243ee994a52f57c371f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating full split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits dict_keys(['full'])\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "#check for the types of splits in the dataset\n",
    "dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_meta_All_Beauty\")\n",
    "print(f\"Dataset splits {dataset.keys()}\")\n",
    "\n",
    "dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_All_Beauty\")\n",
    "print(f\"Dataset splits {dataset.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75b082e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to access the chunk of data from the All_Beauty category\n",
      "Finished accessing the chunck of data from the All_Beauty category 1/34 completed\n",
      "Starting to access the chunk of data from the Amazon_Fashion category\n",
      "Finished accessing the chunck of data from the Amazon_Fashion category 2/34 completed\n",
      "Starting to access the chunk of data from the Appliances category\n",
      "Finished accessing the chunck of data from the Appliances category 3/34 completed\n",
      "Starting to access the chunk of data from the Arts_Crafts_and_Sewing category\n",
      "Finished accessing the chunck of data from the Arts_Crafts_and_Sewing category 4/34 completed\n",
      "Starting to access the chunk of data from the Automotive category\n",
      "Finished accessing the chunck of data from the Automotive category 5/34 completed\n",
      "Starting to access the chunk of data from the Baby_Products category\n",
      "Finished accessing the chunck of data from the Baby_Products category 6/34 completed\n",
      "Starting to access the chunk of data from the Beauty_and_Personal_Care category\n",
      "Finished accessing the chunck of data from the Beauty_and_Personal_Care category 7/34 completed\n",
      "Starting to access the chunk of data from the Books category\n",
      "Finished accessing the chunck of data from the Books category 8/34 completed\n",
      "Starting to access the chunk of data from the CDs_and_Vinyl category\n",
      "Finished accessing the chunck of data from the CDs_and_Vinyl category 9/34 completed\n",
      "Starting to access the chunk of data from the Cell_Phones_and_Accessories category\n",
      "Finished accessing the chunck of data from the Cell_Phones_and_Accessories category 10/34 completed\n",
      "Starting to access the chunk of data from the Clothing_Shoes_and_Jewelry category\n",
      "Finished accessing the chunck of data from the Clothing_Shoes_and_Jewelry category 11/34 completed\n",
      "Starting to access the chunk of data from the Digital_Music category\n",
      "Finished accessing the chunck of data from the Digital_Music category 12/34 completed\n",
      "Starting to access the chunk of data from the Electronics category\n",
      "Finished accessing the chunck of data from the Electronics category 13/34 completed\n",
      "Starting to access the chunk of data from the Gift_Cards category\n",
      "Finished accessing the chunck of data from the Gift_Cards category 14/34 completed\n",
      "Starting to access the chunk of data from the Grocery_and_Gourmet_Food category\n",
      "Finished accessing the chunck of data from the Grocery_and_Gourmet_Food category 15/34 completed\n",
      "Starting to access the chunk of data from the Handmade_Products category\n",
      "Finished accessing the chunck of data from the Handmade_Products category 16/34 completed\n",
      "Starting to access the chunk of data from the Health_and_Household category\n",
      "Finished accessing the chunck of data from the Health_and_Household category 17/34 completed\n",
      "Starting to access the chunk of data from the Health_and_Personal_Care category\n",
      "Finished accessing the chunck of data from the Health_and_Personal_Care category 18/34 completed\n",
      "Starting to access the chunk of data from the Home_and_Kitchen category\n",
      "Finished accessing the chunck of data from the Home_and_Kitchen category 19/34 completed\n",
      "Starting to access the chunk of data from the Industrial_and_Scientific category\n",
      "Finished accessing the chunck of data from the Industrial_and_Scientific category 20/34 completed\n",
      "Starting to access the chunk of data from the Kindle_Store category\n",
      "Finished accessing the chunck of data from the Kindle_Store category 21/34 completed\n",
      "Starting to access the chunk of data from the Magazine_Subscriptions category\n",
      "Finished accessing the chunck of data from the Magazine_Subscriptions category 22/34 completed\n",
      "Starting to access the chunk of data from the Movies_and_TV category\n",
      "Finished accessing the chunck of data from the Movies_and_TV category 23/34 completed\n",
      "Starting to access the chunk of data from the Musical_Instruments category\n",
      "Finished accessing the chunck of data from the Musical_Instruments category 24/34 completed\n",
      "Starting to access the chunk of data from the Office_Products category\n",
      "Finished accessing the chunck of data from the Office_Products category 25/34 completed\n",
      "Starting to access the chunk of data from the Patio_Lawn_and_Garden category\n",
      "Finished accessing the chunck of data from the Patio_Lawn_and_Garden category 26/34 completed\n",
      "Starting to access the chunk of data from the Pet_Supplies category\n",
      "Finished accessing the chunck of data from the Pet_Supplies category 27/34 completed\n",
      "Starting to access the chunk of data from the Software category\n",
      "Finished accessing the chunck of data from the Software category 28/34 completed\n",
      "Starting to access the chunk of data from the Sports_and_Outdoors category\n",
      "Finished accessing the chunck of data from the Sports_and_Outdoors category 29/34 completed\n",
      "Starting to access the chunk of data from the Subscription_Boxes category\n",
      "Finished accessing the chunck of data from the Subscription_Boxes category 30/34 completed\n",
      "Starting to access the chunk of data from the Tools_and_Home_Improvement category\n",
      "Finished accessing the chunck of data from the Tools_and_Home_Improvement category 31/34 completed\n",
      "Starting to access the chunk of data from the Toys_and_Games category\n",
      "Finished accessing the chunck of data from the Toys_and_Games category 32/34 completed\n",
      "Starting to access the chunk of data from the Video_Games category\n",
      "Finished accessing the chunck of data from the Video_Games category 33/34 completed\n",
      "Starting to access the chunk of data from the Unknown category\n",
      "Finished accessing the chunck of data from the Unknown category 34/34 completed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def huggingface_streaming_chunks_from_categories(dataset_name, config_name, split= \"full\", chunk_size= 10000):\n",
    "    \n",
    "    chunks = load_dataset(dataset_name, name=config_name, split=split, streaming=True)\n",
    "    \n",
    "    chunk= [sample for _, sample in zip(range(chunk_size), chunks)]\n",
    "\n",
    "    return Dataset.from_list(chunk)\n",
    "\n",
    "categories= [\n",
    "    \"All_Beauty\", \"Amazon_Fashion\", \"Appliances\", \"Arts_Crafts_and_Sewing\", \"Automotive\",\n",
    "    \"Baby_Products\", \"Beauty_and_Personal_Care\", \"Books\", \"CDs_and_Vinyl\",\n",
    "    \"Cell_Phones_and_Accessories\", \"Clothing_Shoes_and_Jewelry\", \"Digital_Music\", \"Electronics\",\n",
    "    \"Gift_Cards\", \"Grocery_and_Gourmet_Food\", \"Handmade_Products\", \"Health_and_Household\",\n",
    "    \"Health_and_Personal_Care\", \"Home_and_Kitchen\", \"Industrial_and_Scientific\", \"Kindle_Store\",\n",
    "    \"Magazine_Subscriptions\", \"Movies_and_TV\", \"Musical_Instruments\", \"Office_Products\",\n",
    "    \"Patio_Lawn_and_Garden\", \"Pet_Supplies\", \"Software\", \"Sports_and_Outdoors\",\n",
    "    \"Subscription_Boxes\", \"Tools_and_Home_Improvement\", \"Toys_and_Games\", \"Video_Games\", \"Unknown\"\n",
    "] \n",
    "  \n",
    "count = 1\n",
    "\n",
    "for category in categories:\n",
    "    print(f\"Starting to access the chunk of data from the {category} category\")\n",
    "\n",
    "    review_chunk= huggingface_streaming_chunks_from_categories(\"McAuley-Lab/Amazon-Reviews-2023\", f\"raw_review_{category}\")\n",
    "    review_chunk_data = pd.DataFrame(review_chunk)\n",
    "    review_chunk_data.to_csv(f\"{category}_review.csv\", index=False)\n",
    "\n",
    "    meta_chunk= huggingface_streaming_chunks_from_categories(\"McAuley-Lab/Amazon-Reviews-2023\", f\"raw_meta_{category}\")\n",
    "    meta_chunk_data = pd.DataFrame(meta_chunk)\n",
    "    meta_chunk_data.to_csv(f\"{category}_meta.csv\", index=False)\n",
    "\n",
    "    print(f\"Finished accessing the chunck of data from the {category} category {count}/34 completed\")\n",
    "    count = count + 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
